{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a GMM to the AdVitam Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 1px solid white;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order of appearance\n",
    "from useful_functions.check_for_missing_data import check_for_missing_data\n",
    "\n",
    "# physio data\n",
    "from useful_functions.physio_data.pd_dictionary import create_pd_dictionary\n",
    "from useful_functions.physio_data.process_physio_timestamps import process_physio_timestamps\n",
    "from useful_functions.physio_data.preprocess_physio_data import preprocess_physio_data\n",
    "\n",
    "from useful_functions.demographic_data.process_driver_demographic_data import (\n",
    "    process_driver_demographic_data,\n",
    ")\n",
    "\n",
    "from useful_functions.construct_observations import construct_observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the folder paths to raw data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driving_data_folder = \"../AdVitam/Exp2/Raw/Driving\"\n",
    "physio_data_folder = \"../AdVitam/Exp2/Raw/Physio/Txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing a list of driver files to exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers_to_exclude = check_for_missing_data(driving_data_folder, physio_data_folder)\n",
    "drivers_to_exclude.extend([\"NST77\", \"NST11\", \"ST22\", \"NST87\", \"ST14\", \"ST12\", \"NST73\", \"ST10\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`check_for_missing_data()` returns a list of any driver that is _not_ in both the `driving` and `physio` folders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Participants: ST22, NST87, ST14, ST12, NST73 and ST10 seem to have issues with there physiological data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data + Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Physiological Signals & Markers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 1px dashed white; border-bottom: 0px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Signals:**\n",
    "\n",
    "| Feature | Description            | Notes  |\n",
    "| ------- | ---------------------- | ------ |\n",
    "| min     | Time Elapsed           |        |\n",
    "| ECG     | Electrocardiogram      | 1000Hz |\n",
    "| EDA     | Electrodermal Activity | 1000Hz |\n",
    "| RESP    | Resperatory            | 1000Hz |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Markers:**\n",
    "\n",
    "Contains the timestamps for each period of the experiment.\n",
    "\n",
    "- Training1 = Baseline phase\n",
    "- Training2 = Practice phase in the driving simulator\n",
    "- Driving = Main driving session in conditionally automated driving.\n",
    "\n",
    "Be careful, the timestamps are here in seconds while they are in minutes in the raw data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Timestamps:**\n",
    "\n",
    "Time elapsed (in seconds) between the start of the main driving session and the appearance of the obstacles.\n",
    "\n",
    "- TrigObsX: the time when the driver pressed the button to report having understood the situation\n",
    "- DetObsX: and the time when the driver actually took over control\n",
    "- RepObsX: X corresponds to one of obstacle or the false alarm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physio data dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a dictionary of the raw physiological data and their markers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "phsyiological_data_dictionary = create_pd_dictionary(physio_data_folder, drivers_to_exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`create_pd_dictionary()` stores every file in the `physio_data_folder` in a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing the Physiological data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "phsyiological_data_dictionary = preprocess_physio_data(phsyiological_data_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`process_physio_data()` resamples the data to 10ms (100Hz) and then segments the data into each experimental phase (Baseline, Training, Driving)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physio timestamps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataframe to store the trigger time, takeover time, release time, and TOT for each obstacle, for every driver. Similar to `driver_timestamps`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "physio_timestamps = pd.read_csv(\n",
    "    \"../AdVitam/Exp2/Preprocessed/Physio and Driving/timestamps_obstacles.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Physio Timestamps\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Change column names to match driving timestamps\n",
    "1. Remove preselected drivers\n",
    "1. Reformat subject id to match\n",
    "1. Transfrom timestamps into timedelta objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "physio_timestamps = process_physio_timestamps(physio_timestamps, drivers_to_exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver Demographic Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 1px dashed white; border-bottom: 0px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Driver Demographic Data Description:**\n",
    "| Feature | Description | Note |\n",
    "| --- | --- | --- |\n",
    "| code | Code of driver Secondary Task (ST) vs No ST (NST) + unique id (1,2,...) | In the form (ST/NST)# |\n",
    "| date | Day of data collection | Removed |\n",
    "| time | Hour of data collection | Removed |\n",
    "| condition | Experimental condition for mental workload | Removed (contained in driver code |\n",
    "| sex | driver sex | |\n",
    "| age | Age of drivers in years | |\n",
    "| mothertongue | drivers first language | |\n",
    "| education | Highest education degree | |\n",
    "| driving_license | Year of obtenstion of driving license | |\n",
    "| km_year | Number of kilometers covered per year in average | |\n",
    "| accidents | Number of accidents during the last 3 years | |\n",
    "| nasa_tlx_N | Answer to the NASA TLX for question N | Removed |\n",
    "| danger_O | Subjective ranking of the danger of obstacle O | Removed |\n",
    "| realism_O | Subjective ranking of the realism of obstacle O | Removed |\n",
    "| sart_N_O | Subjective answer to the sart for question N related to obstacle O | Removed |\n",
    "| demand_O | Demands on attentional resources (complexity, variability, and instability of the situation) | Removed |\n",
    "| supply_O | Supply of attentional resources (division of attention, arousal, concentration, and spare mental capacity) | Removed |\n",
    "| understanding_O | Understanding of the situation (information quantity, information quality and familiarity). | Removed |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driver Demographic Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grabbing the driver demographic data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_demographic_data = pd.read_csv(\n",
    "    \"../AdVitam/Exp2/Preprocessed/Questionnaires/Exp2_Database.csv\",\n",
    "    usecols=[\n",
    "        \"code\",\n",
    "        \"sex\",\n",
    "        \"age\",\n",
    "        \"mothertongue\",\n",
    "        \"education\",\n",
    "        \"driving_license\",\n",
    "        \"km_year\",\n",
    "        \"accidents\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing driver demographic data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "1. Remove preselected drivers\n",
    "2. Reformat code to match data\n",
    "3. Coverting driving licence from year obtained to of years obtained\n",
    "4. Normalize km/y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_demographic_data = process_driver_demographic_data(\n",
    "    driver_demographic_data, drivers_to_exclude\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing Sequence of Observations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to train 2 HMM trained to observations assosiated with a 'slow' takeover, and a 'fast' takeover.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "merge() missing 1 required positional argument: 'right'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m physio_data_10_sec\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m physio_data_10_sec\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m-\u001b[39m physio_data_10_sec\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mmin()\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# merge the data\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m driver_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mphysio_data_10_sec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# reset the index\u001b[39;00m\n\u001b[1;32m     68\u001b[0m driver_data\u001b[38;5;241m.\u001b[39mreset_index(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: merge() missing 1 required positional argument: 'right'"
     ]
    }
   ],
   "source": [
    "# initialize lists to store observations\n",
    "slow_observations = []\n",
    "fast_observations = []\n",
    "\n",
    "# loop through each driver\n",
    "for driver in phsyiological_data_dictionary.keys():\n",
    "    # data for each driver\n",
    "    driver_phyio_baseline_data = phsyiological_data_dictionary[driver][\"baseline\"]\n",
    "    driver_physio_data = phsyiological_data_dictionary[driver][\"driving\"]\n",
    "\n",
    "    # timestamps\n",
    "    driver_physio_timestamps = physio_timestamps[physio_timestamps[\"subject_id\"] == driver]\n",
    "\n",
    "    # loop through every takeover\n",
    "    for column in driver_physio_timestamps.columns:\n",
    "        if \"TOT\" in column:\n",
    "            # get the obstacle number\n",
    "            obstacle = column.replace(\"TOT\", \"\")\n",
    "\n",
    "            # store the obstacle triggers for driving and physio\n",
    "            physio_obstacle_trigger = driver_physio_timestamps[\"Triggered\" + obstacle].iloc[0]\n",
    "\n",
    "            # check if the obstacle triggers are not null\n",
    "            if pd.isnull(physio_obstacle_trigger):\n",
    "                continue\n",
    "\n",
    "            # trim the data to the 10s before the takeover\n",
    "            physio_data_10_sec = driver_physio_data[\n",
    "                (\n",
    "                    driver_physio_data[\"Time\"]\n",
    "                    >= (\n",
    "                        driver_physio_data.Time.min()\n",
    "                        + physio_obstacle_trigger\n",
    "                        - pd.to_timedelta(\"10s\")\n",
    "                    )\n",
    "                )\n",
    "                & (\n",
    "                    driver_physio_data[\"Time\"]\n",
    "                    < driver_physio_data.Time.min() + physio_obstacle_trigger\n",
    "                )\n",
    "            ].copy()\n",
    "\n",
    "            # # Store the Difference between the baseline and the takeover\n",
    "            # hrv_difference = takeover_hrv - baseline_hrv\n",
    "\n",
    "            # # rename the columns\n",
    "            # hrv_difference.columns = [\n",
    "            #     \"HRV_\" + column + \"_Difference\" for column in hrv_difference.columns\n",
    "            # ]\n",
    "\n",
    "            # # concatenate the dataframes\n",
    "            # hrv = pd.concat([baseline_hrv, takeover_hrv, hrv_difference], axis=1)\n",
    "\n",
    "            # reset the Time index\n",
    "            physio_data_10_sec = physio_data_10_sec.set_index(\"Time\")\n",
    "\n",
    "            # set the index to 0\n",
    "            physio_data_10_sec.index = physio_data_10_sec.index - physio_data_10_sec.index.min()\n",
    "\n",
    "            # merge the data\n",
    "            driver_data = pd.merge(\n",
    "                physio_data_10_sec,\n",
    "                left_index=True,\n",
    "                right_index=True,\n",
    "            )\n",
    "\n",
    "            # reset the index\n",
    "            driver_data.reset_index(inplace=True)\n",
    "\n",
    "            # Remove Time, Position X, Position Y, Position Z, Autonomous Mode (T/F), Obstacles\n",
    "            driver_data = driver_data.drop(\n",
    "                columns=[\n",
    "                    \"Time\",\n",
    "                    \"Autonomous Mode (T/F)\",\n",
    "                    \"Obstacles\",\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # grab driver demogrpahic data\n",
    "            demo_data = driver_demographic_data[driver_demographic_data[\"code\"] == driver]\n",
    "\n",
    "            # Broadcast to repeat the static data for each row of the dynamic data\n",
    "            demo_data = pd.concat([demo_data] * len(driver_data), ignore_index=True)\n",
    "\n",
    "            # Broadcast the hrv data\n",
    "            # hrv = pd.concat([hrv] * len(driver_data), ignore_index=True)\n",
    "\n",
    "            # merge the data\n",
    "            driver_data = pd.merge(driver_data, demo_data, left_index=True, right_index=True)\n",
    "            # driver_data = pd.merge(driver_data, hrv, left_index=True, right_index=True)\n",
    "\n",
    "            # change the code value to the driver id\n",
    "            driver_data[\"code\"] = driver_data[\"code\"].apply(lambda x: x.split(\"T\")[1])\n",
    "            # cast code to int\n",
    "            driver_data[\"code\"] = driver_data[\"code\"].astype(int)\n",
    "\n",
    "            if len(driver_data) != 1000:\n",
    "                continue\n",
    "\n",
    "            # determine if the takeover was slow or fast\n",
    "            if physio_timestamps[column].iloc[0] > pd.to_timedelta(\"3s\"):\n",
    "                slow_observations.append(driver_data.to_numpy())\n",
    "            else:\n",
    "                fast_observations.append(driver_data.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the HMMs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train/Validate/Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_observations_train, slow_observations_test = train_test_split(\n",
    "    slow_observations, test_size=0.1\n",
    ")\n",
    "\n",
    "fast_observations_train, fast_observations_test = train_test_split(\n",
    "    fast_observations, test_size=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, error_score=&#x27;raise&#x27;,\n",
       "                   estimator=GaussianMixture(reg_covar=0.0001), n_iter=1000,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;covariance_type&#x27;: [&#x27;full&#x27;, &#x27;tied&#x27;,\n",
       "                                                            &#x27;diag&#x27;,\n",
       "                                                            &#x27;spherical&#x27;],\n",
       "                                        &#x27;init_params&#x27;: [&#x27;kmeans&#x27;, &#x27;k-means++&#x27;,\n",
       "                                                        &#x27;random&#x27;,\n",
       "                                                        &#x27;random_from_data&#x27;],\n",
       "                                        &#x27;max_iter&#x27;: array([  100,   200,   300,   400,   500,   600,   700,   800,   900,\n",
       "        1000,  1100,  1200,  1300,  1400,  1500,  1600,  1700,  1800,\n",
       "        19...\n",
       "        6400,  6500,  6600,  6700,  6800,  6900,  7000,  7100,  7200,\n",
       "        7300,  7400,  7500,  7600,  7700,  7800,  7900,  8000,  8100,\n",
       "        8200,  8300,  8400,  8500,  8600,  8700,  8800,  8900,  9000,\n",
       "        9100,  9200,  9300,  9400,  9500,  9600,  9700,  9800,  9900,\n",
       "       10000]),\n",
       "                                        &#x27;n_components&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       "                                        &#x27;random_state&#x27;: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       "                                        &#x27;tol&#x27;: array([0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009,\n",
       "       0.01 ])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, error_score=&#x27;raise&#x27;,\n",
       "                   estimator=GaussianMixture(reg_covar=0.0001), n_iter=1000,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;covariance_type&#x27;: [&#x27;full&#x27;, &#x27;tied&#x27;,\n",
       "                                                            &#x27;diag&#x27;,\n",
       "                                                            &#x27;spherical&#x27;],\n",
       "                                        &#x27;init_params&#x27;: [&#x27;kmeans&#x27;, &#x27;k-means++&#x27;,\n",
       "                                                        &#x27;random&#x27;,\n",
       "                                                        &#x27;random_from_data&#x27;],\n",
       "                                        &#x27;max_iter&#x27;: array([  100,   200,   300,   400,   500,   600,   700,   800,   900,\n",
       "        1000,  1100,  1200,  1300,  1400,  1500,  1600,  1700,  1800,\n",
       "        19...\n",
       "        6400,  6500,  6600,  6700,  6800,  6900,  7000,  7100,  7200,\n",
       "        7300,  7400,  7500,  7600,  7700,  7800,  7900,  8000,  8100,\n",
       "        8200,  8300,  8400,  8500,  8600,  8700,  8800,  8900,  9000,\n",
       "        9100,  9200,  9300,  9400,  9500,  9600,  9700,  9800,  9900,\n",
       "       10000]),\n",
       "                                        &#x27;n_components&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       "                                        &#x27;random_state&#x27;: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       "                                        &#x27;tol&#x27;: array([0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009,\n",
       "       0.01 ])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GaussianMixture</label><div class=\"sk-toggleable__content\"><pre>GaussianMixture(reg_covar=0.0001)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianMixture</label><div class=\"sk-toggleable__content\"><pre>GaussianMixture(reg_covar=0.0001)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "                   estimator=GaussianMixture(reg_covar=0.0001), n_iter=1000,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'covariance_type': ['full', 'tied',\n",
       "                                                            'diag',\n",
       "                                                            'spherical'],\n",
       "                                        'init_params': ['kmeans', 'k-means++',\n",
       "                                                        'random',\n",
       "                                                        'random_from_data'],\n",
       "                                        'max_iter': array([  100,   200,   300,   400,   500,   600,   700,   800,   900,\n",
       "        1000,  1100,  1200,  1300,  1400,  1500,  1600,  1700,  1800,\n",
       "        19...\n",
       "        6400,  6500,  6600,  6700,  6800,  6900,  7000,  7100,  7200,\n",
       "        7300,  7400,  7500,  7600,  7700,  7800,  7900,  8000,  8100,\n",
       "        8200,  8300,  8400,  8500,  8600,  8700,  8800,  8900,  9000,\n",
       "        9100,  9200,  9300,  9400,  9500,  9600,  9700,  9800,  9900,\n",
       "       10000]),\n",
       "                                        'n_components': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       "                                        'random_state': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       "                                        'tol': array([0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009,\n",
       "       0.01 ])})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing the hyperparameters\n",
    "n_components = np.arange(1, 11)\n",
    "covariance_type = [\"full\", \"tied\", \"diag\", \"spherical\"]\n",
    "tol = np.arange(0.001, 0.011, 0.001)\n",
    "init_params = [\"kmeans\", \"k-means++\", \"random\", \"random_from_data\"]\n",
    "random_state = np.arange(0, 11)\n",
    "max_iter = np.linspace(100, 10000, 100).astype(int)\n",
    "\n",
    "hyperparametes = {\n",
    "    \"n_components\": n_components,\n",
    "    \"covariance_type\": covariance_type,\n",
    "    \"tol\": tol,\n",
    "    \"init_params\": init_params,\n",
    "    \"random_state\": random_state,\n",
    "    \"max_iter\": max_iter,\n",
    "}\n",
    "\n",
    "# initialize the model\n",
    "slow_model = GaussianMixture(reg_covar=1e-4)\n",
    "fast_model = GaussianMixture(reg_covar=1e-4)\n",
    "\n",
    "# initialize the random search\n",
    "slow_random_search = RandomizedSearchCV(\n",
    "    slow_model, hyperparametes, n_iter=1000, cv=5, n_jobs=-1, error_score='raise'\n",
    ")\n",
    "fast_random_search = RandomizedSearchCV(\n",
    "    fast_model, hyperparametes, n_iter=1000, cv=5,  n_jobs=-1, error_score='raise'\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "s = np.vstack(slow_observations_train)\n",
    "slow_random_search.fit(s)\n",
    "f = np.vstack(fast_observations_train)\n",
    "fast_random_search.fit(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianMixture(init_params=&#x27;random&#x27;, max_iter=2800, n_components=9,\n",
       "                random_state=0, reg_covar=0.0001, tol=0.007)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianMixture</label><div class=\"sk-toggleable__content\"><pre>GaussianMixture(init_params=&#x27;random&#x27;, max_iter=2800, n_components=9,\n",
       "                random_state=0, reg_covar=0.0001, tol=0.007)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianMixture(init_params='random', max_iter=2800, n_components=9,\n",
       "                random_state=0, reg_covar=0.0001, tol=0.007)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_model = slow_random_search.best_estimator_\n",
    "fast_model = fast_random_search.best_estimator_\n",
    "\n",
    "slow_model.fit(s)\n",
    "fast_model.fit(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5161290322580645\n"
     ]
    }
   ],
   "source": [
    "# test the HMM\n",
    "accuracy = 0\n",
    "\n",
    "for obs in slow_observations_test:\n",
    "    if slow_model.score(obs) > fast_model.score(obs):\n",
    "        accuracy += 1\n",
    "\n",
    "for obs in fast_observations_test:\n",
    "    if fast_model.score(obs) > slow_model.score(obs):\n",
    "        accuracy += 1\n",
    "\n",
    "accuracy = accuracy / (len(slow_observations_test) + len(fast_observations_test))\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# initialize the grid search cv\\nslow_grid = GridSearchCV(slow_model, hyperparametes, cv=5, n_jobs=-1, verbose=1)\\nfast_grid = GridSearchCV(fast_model, hyperparametes, cv=5, n_jobs=-1, verbose=1)\\n\\n# fit the model\\ns = np.vstack(slow_observations_train)\\nslow_grid.fit(s)\\nf = np.vstack(fast_observations_train)\\nfast_grid.fit(f)\\n\\n# get the best estimators\\nslow_hmm = slow_grid.best_estimator_\\nfast_hmm = fast_grid.best_estimator_\\n\\nslow_hmm.fit(s)\\nfast_hmm.fit(f)\\n\\n# test the HMM\\naccuracy = 0\\n\\nfor obs in slow_observations_test:\\n    if slow_hmm.score(obs) > fast_hmm.score(obs):\\n        accuracy += 1\\n\\nfor obs in fast_observations_test:\\n    if fast_hmm.score(obs) > slow_hmm.score(obs):\\n        accuracy += 1\\n\\naccuracy = accuracy / (len(slow_observations_test) + len(fast_observations_test))\\nprint(\"Accuracy: \", accuracy)\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# initialize the grid search cv\n",
    "slow_grid = GridSearchCV(slow_model, hyperparametes, cv=5, n_jobs=-1, verbose=1)\n",
    "fast_grid = GridSearchCV(fast_model, hyperparametes, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# fit the model\n",
    "s = np.vstack(slow_observations_train)\n",
    "slow_grid.fit(s)\n",
    "f = np.vstack(fast_observations_train)\n",
    "fast_grid.fit(f)\n",
    "\n",
    "# get the best estimators\n",
    "slow_hmm = slow_grid.best_estimator_\n",
    "fast_hmm = fast_grid.best_estimator_\n",
    "\n",
    "slow_hmm.fit(s)\n",
    "fast_hmm.fit(f)\n",
    "\n",
    "# test the HMM\n",
    "accuracy = 0\n",
    "\n",
    "for obs in slow_observations_test:\n",
    "    if slow_hmm.score(obs) > fast_hmm.score(obs):\n",
    "        accuracy += 1\n",
    "\n",
    "for obs in fast_observations_test:\n",
    "    if fast_hmm.score(obs) > slow_hmm.score(obs):\n",
    "        accuracy += 1\n",
    "\n",
    "accuracy = accuracy / (len(slow_observations_test) + len(fast_observations_test))\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Accuracy Including Every Feature:\n",
    "51.61%\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
