{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a HMM to the AdVitam Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Overview:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting a [Hidden Markov Model (HMM)](https://en.wikipedia.org/wiki/Hidden_Markov_model) to the [AdVitam](https://doi.org/10.1016/j.dib.2023.109027) dataset.\n",
    "\n",
    "- HMM was implemented using the [hmmlearn](https://hmmlearn.readthedocs.io/en/latest/index.html) python library.\n",
    "\n",
    "<br></br>\n",
    "\n",
    "**Defining Takeover Quality Quantitatively**\n",
    "\n",
    "This is typically done using one or more of these 3 metrics:\n",
    "\n",
    "- Takeover Time (TOT)\n",
    "- Sudden Vehicle Deviation\n",
    "- Response Budget\n",
    "\n",
    "<br></br>\n",
    "\n",
    "**References:**\n",
    "\n",
    "- Lawrence R. Rabiner “A tutorial on hidden Markov models and selected applications in speech recognition”, Proceedings of the IEEE 77.2, pp. 257-286, 1989.\n",
    "- Jeff A. Bilmes, “A gentle tutorial of the EM algorithm and its application to parameter estimation for Gaussian mixture and hidden Markov models.”, 1998.\n",
    "- Mark Stamp. “[A revealing introduction to hidden Markov models](<(http://www.cs.sjsu.edu/~stamp/RUA/HMM.pdf)>)”. Tech. rep. Department of Computer Science, San Jose State University, 2018.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 1px solid white;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import hmmlearn.hmm as hmm\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import (\n",
    "    cross_validate,\n",
    "    RandomizedSearchCV,\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from useful_functions.driving_data.dd_dictionary import create_dd_dictionary\n",
    "from useful_functions.driving_data.process_driving_data import processing_driving_data\n",
    "\n",
    "from useful_functions.physio_data.pd_dictionary import create_pd_dictionary\n",
    "from useful_functions.physio_data.process_physio_timestamps import process_physio_timestamps\n",
    "from useful_functions.physio_data.process_physio_data import process_physio_data\n",
    "\n",
    "from useful_functions.demographic_data.process_driver_demographic_data import (\n",
    "    process_driver_demographic_data,\n",
    ")\n",
    "\n",
    "from useful_functions.construct_observations import construct_observations\n",
    "\n",
    "from useful_functions.takeover_dataframe import create_takeover_timestamps\n",
    "from useful_functions.check_for_missing_data import check_for_missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data + Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the folder paths to raw data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driving_data_folder = \"../AdVitam/Exp2/Raw/Driving\"\n",
    "physio_data_folder = \"../AdVitam/Exp2/Raw/Physio/Txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing a list of participants to exclude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants_to_exclude = check_for_missing_data(driving_data_folder, physio_data_folder)\n",
    "participants_to_exclude.append(\"NST77\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Participants Excluded:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Participant       | Reason                                                                                          |\n",
    "| ----------------- | ----------------------------------------------------------------------------------------------- |\n",
    "| NST77             | Driving file contains obstacles = \"TriggeredObs2TriggeredObs3\" and \"TriggeredObs3TriggeredObs4\" |\n",
    "| NST91, ST84, ST60 | Does not contain a physio file                                                                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driving Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 1px dashed white; border-bottom: 0px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Driver Data:**\n",
    "| Feature | Description | Notes |\n",
    "| --- | --- | --- |\n",
    "| Time | Time elapsed since the software was launched (in seconds) | |\n",
    "| EngineSpeed | Engine speed (in rpm) | Removed |\n",
    "| GearPosActual | Current gear | Removed |\n",
    "| GearPosTarget | Next planned gear | Removed |\n",
    "| AcceleratorPedalPos | Position of gas pedal. | Recording problem, Removed |\n",
    "| DeceleratorPedalPos | Position of brake pedal. | Recording problem, Removed |\n",
    "| SteeringWheelAngle | Steering wheel angle (in degrees) | |\n",
    "| VehicleSpeed | Vehicle speed (in mph) | |\n",
    "| Position X | Vehicle position along the x-axis in the simulated driving environment | |\n",
    "| Position Y | Vehicle position along the y-axis in the simulated driving environment | |\n",
    "| Position Z | Vehicle position along the z-axis in the simulated driving environment | |\n",
    "| Autonomous Mode (T/F) | Autonomous pilot status. | True = Activated, False = Deactivated (driver in control) |\n",
    "| Obstacles | Events that occurred during the driving simulation. | See Below |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obstacles:**\n",
    "\n",
    "| Event         | Description                                                                                                                                                                                             |\n",
    "| ------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| TriggeredObsX | Time at which each takeover request was triggered by the experimenter                                                                                                                                   |\n",
    "| Obs1          | Deer                                                                                                                                                                                                    |\n",
    "| Obs2          | Traffic cone                                                                                                                                                                                            |\n",
    "| Obs3          | Frog                                                                                                                                                                                                    |\n",
    "| Obs4          | Traffic cone                                                                                                                                                                                            |\n",
    "| Obs5          | False alarm (x2)                                                                                                                                                                                        |\n",
    "| Detected      | Time at which the driver pressed the steering wheel button to notify he/she understood the situation. The driver is in control of the car when the value of the column \"Autonomous Mode (T/F)\" is False |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driving Data Dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a dictionary of the raw driving data files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driving_data_dictionary = create_dd_dictionary(driving_data_folder, participants_to_exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing driving data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps Taken\n",
    "\n",
    "1. Label encode the `Obstacles` column\n",
    "2. Fill `Obstacles` column with `Nothing`\n",
    "3. Convert `Time` column to pandas timedelta\n",
    "4. Resample driver data to 10ms (100Hz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a Label Encoder to the Obstacles\n",
    "driver_data = driving_data_dictionary[\"NST01\"]\n",
    "driver_data = driver_data.fillna(\"Nothing\")\n",
    "enc = preprocessing.LabelEncoder()\n",
    "enc.fit(driver_data[\"Obstacles\"])\n",
    "\n",
    "# Processing the Driving Data\n",
    "driving_data_dictionary = processing_driving_data(driving_data_dictionary, enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating driving data takeover timestamps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created a dataframe to store the trigger time, takeover time, release time, and TOT for each obstacle, for every participant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "driving_timestamps = create_takeover_timestamps(driving_data_dictionary, enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Physiological Signals & Markers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 1px dashed white; border-bottom: 0px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Signals:**\n",
    "\n",
    "| Feature | Description            | Notes  |\n",
    "| ------- | ---------------------- | ------ |\n",
    "| min     | Time Elapsed           |        |\n",
    "| ECG     | Electrocardiogram      | 1000Hz |\n",
    "| EDA     | Electrodermal Activity | 1000Hz |\n",
    "| RESP    | Resperatory            | 1000Hz |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Markers:**\n",
    "\n",
    "Contains the timestamps for each period of the experiment.\n",
    "\n",
    "- Training1 = Baseline phase\n",
    "- Training2 = Practice phase in the driving simulator\n",
    "- Driving = Main driving session in conditionally automated driving.\n",
    "\n",
    "Be careful, the timestamps are here in seconds while they are in minutes in the raw data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Timestamps:**\n",
    "\n",
    "Time elapsed (in seconds) between the start of the main driving session and the appearance of the obstacles.\n",
    "\n",
    "- TrigObsX: the time when the driver pressed the button to report having understood the situation\n",
    "- DetObsX: and the time when the driver actually took over control\n",
    "- RepObsX: X corresponds to one of obstacle or the false alarm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physio data dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a dictionary of the raw physiological data and their markers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "phsyiological_data_dictionary = create_pd_dictionary(physio_data_folder, participants_to_exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physio timestamps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataframe to store the trigger time, takeover time, release time, and TOT for each obstacle, for every participant. Similar to `driver_timestamps`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "physio_timestamps = pd.read_csv(\n",
    "    \"../AdVitam/Exp2/Preprocessed/Physio and Driving/timestamps_obstacles.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Physio Timestamps\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Change column names to match driving timestamps\n",
    "1. Remove preselected participants\n",
    "1. Reformat subject id to match\n",
    "1. Transfrom timestamps into timedelta objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "physio_timestamps = process_physio_timestamps(physio_timestamps, participants_to_exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Physiological data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "1. Resampled data to 10ms (100Hz)\n",
    "2. Trimmed the data down to each experimental phase (Baseline, Training, Driving)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "phsyiological_data_dictionary = process_physio_data(phsyiological_data_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver Demographic Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 1px dashed white; border-bottom: 0px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Driver Demographic Data Description:**\n",
    "| Feature | Description | Note |\n",
    "| --- | --- | --- |\n",
    "| code | Code of participant Secondary Task (ST) vs No ST (NST) + unique id (1,2,...) | In the form (ST/NST)# |\n",
    "| date | Day of data collection | Removed |\n",
    "| time | Hour of data collection | Removed |\n",
    "| condition | Experimental condition for mental workload | Removed (contained in participant code |\n",
    "| sex | Participant sex | |\n",
    "| age | Age of participants in years | |\n",
    "| mothertongue | Participants first language | |\n",
    "| education | Highest education degree | |\n",
    "| driving_license | Year of obtenstion of driving license | |\n",
    "| km_year | Number of kilometers covered per year in average | |\n",
    "| accidents | Number of accidents during the last 3 years | |\n",
    "| nasa_tlx_N | Answer to the NASA TLX for question N | Removed |\n",
    "| danger_O | Subjective ranking of the danger of obstacle O | Removed |\n",
    "| realism_O | Subjective ranking of the realism of obstacle O | Removed |\n",
    "| sart_N_O | Subjective answer to the sart for question N related to obstacle O | Removed |\n",
    "| demand_O | Demands on attentional resources (complexity, variability, and instability of the situation) | Removed |\n",
    "| supply_O | Supply of attentional resources (division of attention, arousal, concentration, and spare mental capacity) | Removed |\n",
    "| understanding_O | Understanding of the situation (information quantity, information quality and familiarity). | Removed |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driver Demographic Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grabbing the driver demographic data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_demographic_data = pd.read_csv(\n",
    "    \"../AdVitam/Exp2/Preprocessed/Questionnaires/Exp2_Database.csv\",\n",
    "    usecols=[\n",
    "        \"code\",\n",
    "        \"sex\",\n",
    "        \"age\",\n",
    "        \"mothertongue\",\n",
    "        \"education\",\n",
    "        \"driving_license\",\n",
    "        \"km_year\",\n",
    "        \"accidents\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing driver demographic data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "1. Remove preselected participants\n",
    "2. Reformat code to match data\n",
    "3. Coverting driving licence from year obtained to of years obtained\n",
    "4. Normalize km/y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_demographic_data = process_driver_demographic_data(\n",
    "    driver_demographic_data, participants_to_exclude\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing Sequence of Observations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to train 2 HMM trained to observations assosiated with a 'slow' takeover, and a 'fast' takeover.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_observations, fast_observations = construct_observations(\n",
    "    driving_data_dictionary,\n",
    "    phsyiological_data_dictionary,\n",
    "    driving_timestamps,\n",
    "    physio_timestamps,\n",
    "    driver_demographic_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the HMMs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps:**\n",
    "\n",
    "1. Split the data into training, testing, and validation\n",
    "2. Format the data so it can be read by HMM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "slow_observations_train, slow_observations_test = train_test_split(\n",
    "    slow_observations, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "fast_observations_train, fast_observations_test = train_test_split(\n",
    "    fast_observations, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# create a length array\n",
    "slow_lengths_train = np.array([len(obs) for obs in slow_observations_train])\n",
    "slow_lengths_test = np.array([len(obs) for obs in slow_observations_test])\n",
    "\n",
    "fast_lengths_train = np.array([len(obs) for obs in fast_observations_train])\n",
    "fast_lengths_test = np.array([len(obs) for obs in fast_observations_test])\n",
    "\n",
    "# create a single array for training\n",
    "s = np.vstack(slow_observations_train)\n",
    "f = np.vstack(fast_observations_train)\n",
    "\n",
    "# create a single array for testing\n",
    "s_test = np.vstack(slow_observations_test)\n",
    "f_test = np.vstack(fast_observations_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the hyperparameters\n",
    "n_components = np.arange(1, 11)\n",
    "covariance_type = [\"spherical\", \"diag\", \"full\"]\n",
    "min_covar = np.arange(0.1, 1.1, 0.1)\n",
    "algorithm = [\"viterbi\", \"map\"]\n",
    "random_state = np.arange(1, 11)\n",
    "n_iter = np.arange(1, 11)\n",
    "tol = np.arange(0.001, 0.011, 0.001)\n",
    "verbose = [True, False]\n",
    "hyperparametes = {\n",
    "    \"n_components\": n_components,\n",
    "    \"covariance_type\": covariance_type,\n",
    "    \"min_covar\": min_covar,\n",
    "    \"algorithm\": algorithm,\n",
    "    \"random_state\": random_state,\n",
    "    \"n_iter\": n_iter,\n",
    "    \"tol\": tol,\n",
    "    \"verbose\": verbose,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HMM Classifier\n",
    "class HMMClassifier(BaseEstimator, ClassifierMixin):\n",
    "    # Initializing the model\n",
    "    def __init__(self, n_components=1, covariance_type=\"diag\", min_covar=0.1, algorithm=\"viterbi\", random_state=1, n_iter=1, tol=0.001, verbose=False):\n",
    "        self.n_components = n_components\n",
    "        self.covariance_type = covariance_type\n",
    "        self.min_covar = min_covar\n",
    "        self.algorithm = algorithm\n",
    "        self.random_state = random_state\n",
    "        self.n_iter = n_iter\n",
    "        self.tol = tol\n",
    "        self.verbose = verbose\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        # Assuming X is a list where each element is a sequence of observations\n",
    "        lengths = np.array([len(x) for x in X])\n",
    "        X = np.vstack(X)\n",
    "        self.model = hmm.GaussianHMM(\n",
    "            n_components=self.n_components,\n",
    "            covariance_type=self.covariance_type,\n",
    "            min_covar=self.min_covar,\n",
    "            algorithm=self.algorithm,\n",
    "            random_state=self.random_state,\n",
    "            n_iter=self.n_iter,\n",
    "            tol = self.tol,\n",
    "            verbose=self.verbose,\n",
    "        )\n",
    "        self.model.fit(X, lengths)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Assuming X is a list where each element is a sequence of observations\n",
    "        lengths = np.array([len(x) for x in X])\n",
    "        X = np.vstack(X)\n",
    "        return self.model.predict(X, lengths)\n",
    "\n",
    "    def score(self, X):\n",
    "        # Implement a scoring function, e.g., log likelihood of the data\n",
    "        scores = [self.model.score(x.reshape(-1, 1)) for x in X]\n",
    "        return np.mean(scores)\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        # Return parameters\n",
    "        return {\n",
    "            \"n_components\": self.n_components,\n",
    "            \"covariance_type\": self.covariance_type,\n",
    "            \"min_covar\": self.min_covar,\n",
    "            \"algorithm\": self.algorithm,\n",
    "            \"random_state\": self.random_state,\n",
    "            \"n_iter\": self.n_iter,\n",
    "            \"tol\": self.tol,\n",
    "            \"verbose\": self.verbose,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "slow_model = HMMClassifier()\n",
    "fast_model = HMMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1200000 candidates, totalling 6000000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# initialize the grid search cv\n",
    "slow_grid = GridSearchCV(slow_model, hyperparametes, cv=5, n_jobs=-1, verbose=1)\n",
    "fast_grid = GridSearchCV(fast_model, hyperparametes, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# fit the model\n",
    "slow_grid.fit(s)\n",
    "fast_grid.fit(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train the HMMs\n",
    "# slow_hmm = hmm.GaussianHMM(\n",
    "#     n_components=1,\n",
    "#     random_state=3,\n",
    "# )\n",
    "# slow_hmm.fit(s, slow_lengths_train)\n",
    "\n",
    "# fast_hmm = hmm.GaussianHMM(\n",
    "#     n_components=1,\n",
    "#     random_state=3,\n",
    "# )\n",
    "# fast_hmm.fit(f, fast_lengths_train)\n",
    "\n",
    "# # test the HMM\n",
    "# accuracy = 0\n",
    "\n",
    "# for obs in slow_observations_test:\n",
    "#     if slow_hmm.score(obs) > fast_hmm.score(obs):\n",
    "#         accuracy += 1\n",
    "\n",
    "# for obs in fast_observations_test:\n",
    "#     if fast_hmm.score(obs) > slow_hmm.score(obs):\n",
    "#         accuracy += 1\n",
    "\n",
    "# accuracy = accuracy / (len(slow_observations_test) + len(fast_observations_test))\n",
    "# print(\"Accuracy: \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
